'use client';

import React, { useState, useCallback } from 'react';
import OperationHistory, { OperationRecord } from '@/components/OperationHistory';
import ResizableLayout from '@/components/ResizableLayout';
import VideoUploader from '@/components/VideoUploader';
import SpeechRecognitionPanel from '@/components/SpeechRecognitionPanel';
import VideoUnderstandingPanel from '@/components/VideoUnderstandingPanel';
import SOPEditor from '@/components/SOPEditor';
import { useWebSocket } from '@/hooks/useWebSocket';
import { SOPBlock } from '@/types/sop';
import { notificationManager } from '@/utils/notifications';
import { API_ENDPOINTS } from '@/config/api';

export default function Home() {
  // ç”Ÿæˆå”¯ä¸€çš„å®¢æˆ·ç«¯ä¼šè¯ID
  const [clientSessionId] = useState(() => {
    // å…¼å®¹æ€§æ›´å¥½çš„UUIDç”Ÿæˆæ–¹æ³•
    if (typeof crypto !== 'undefined' && crypto.randomUUID) {
      return crypto.randomUUID();
    }
    // é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ—¶é—´æˆ³å’Œéšæœºæ•°ç”Ÿæˆå”¯ä¸€ID
    return 'client_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  });
  
  // å…¨å±€çŠ¶æ€ç®¡ç†
  const [currentUploadResult, setCurrentUploadResult] = useState<{
    video_url: string;
    audio_url: string;
    session_id: string;
  } | null>(null);
  
  // æœ¬åœ°è§†é¢‘é¢„è§ˆURLï¼ˆç”¨äºSOPç¼–è¾‘å™¨ï¼‰
  const [localVideoPreviewUrl, setLocalVideoPreviewUrl] = useState<string | null>(null);
  
  const [compressionMessage, setCompressionMessage] = useState<{
    type: string;
    message?: string;
    current_frame?: number;
    total_frames?: number;
    percentage?: number;
    [key: string]: unknown;
  } | null>(null);
  const [compressionStatus, setCompressionStatus] = useState<'idle' | 'compressing' | 'completed' | 'error'>('idle');
  
  // è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç›¸å…³çŠ¶æ€
  const [autoSpeechRecognitionTriggered, setAutoSpeechRecognitionTriggered] = useState(false);
  const [autoSpeechRecognitionError, setAutoSpeechRecognitionError] = useState<string | null>(null);
  
  const [operationRecords, setOperationRecords] = useState<OperationRecord[]>([]);
  const [speechRecognitionResult, setSpeechRecognitionResult] = useState<{
    sentence_id: number;
    text: string;
    begin_time: number;
    end_time: number;
    isEdited?: boolean;
    editedText?: string;
  }[] | null>(null);
  
  const [videoUnderstandingResult, setVideoUnderstandingResult] = useState<string>('');
  const [segmentResults, setSegmentResults] = useState<{
    segment_id: number;
    time_range: string;
    result: string;
    status: 'processing' | 'completed' | 'error';
  }[]>([]);
  const [integratedResult, setIntegratedResult] = useState<string>('');
  const [videoUnderstandingPrompt, setVideoUnderstandingPrompt] = useState<string>('');
  const [sopBlocks, setSopBlocks] = useState<SOPBlock[]>([]);

  // å¤„ç†SOPåŒºå—å˜åŒ–
  const handleSopBlocksChange = useCallback((blocks: SOPBlock[]) => {
    setSopBlocks(blocks);
  }, []);

  // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœå˜åŒ–
  const handleSpeechResultsChange = useCallback((results: {
    sentence_id: number;
    text: string;
    begin_time: number;
    end_time: number;
    isEdited?: boolean;
    editedText?: string;
  }[]) => {
    setSpeechRecognitionResult(results);
  }, []);
  const [refinedSopBlocks, setRefinedSopBlocks] = useState<SOPBlock[]>([]);
  const [sopParsePrompt, setSopParsePrompt] = useState<string>('');
  const [sopRefinePrompt, setSopRefinePrompt] = useState<string>('');
  const [notificationEnabled, setNotificationEnabled] = useState(false);

  // WebSocketæ¶ˆæ¯å¤„ç†å‡½æ•°
  const handleWebSocketMessage = useCallback((data: { 
    type: string; 
    [key: string]: unknown;
  }) => {
      if (data.type === 'upload_complete') {
      // å‘é€é€šçŸ¥
      if (notificationEnabled) {
        notificationManager.sendNotification(
          'ğŸ“ è§†é¢‘ä¸Šä¼ å®Œæˆ',
          'è§†é¢‘å’ŒéŸ³é¢‘æ–‡ä»¶å·²æˆåŠŸä¸Šä¼ ï¼Œå¯ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«',
          undefined,
          true
        );
      }

        // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ›´æ–°currentUploadResultï¼Œå› ä¸ºonUploadCompleteå›è°ƒå·²ç»å¤„ç†äº†
        // WebSocketæ¶ˆæ¯ä¸»è¦ç”¨äºé€šçŸ¥ï¼Œä¸åŒ…å«å®Œæ•´çš„uploadResultæ•°æ®
        // è¿™é¿å…äº†é‡å¤çš„æ“ä½œè®°å½•å’ŒçŠ¶æ€è¦†ç›–
      } else if (data.type === 'file_removed') {
        // æ¸…ç©ºå½“å‰ä¸Šä¼ ç»“æœçŠ¶æ€
        setCurrentUploadResult(null);
        
        // é‡ç½®è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çŠ¶æ€
        setAutoSpeechRecognitionTriggered(false);
        setAutoSpeechRecognitionError(null);
        
      // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ·»åŠ æ“ä½œè®°å½•ï¼Œå› ä¸ºonFileRemovedå›è°ƒå·²ç»å¤„ç†äº†
      // è¿™é¿å…äº†é‡å¤çš„æ“ä½œè®°å½•
    } else if (data.type === 'speech_recognition_complete') {
      // å‘é€é€šçŸ¥
      if (notificationEnabled) {
        notificationManager.sendNotification(
          'ğŸ¤ è¯­éŸ³è¯†åˆ«å®Œæˆ',
          'éŸ³é¢‘è½¬å½•å·²å®Œæˆï¼Œå¯ä»¥è¿›è¡Œè§†é¢‘ç†è§£åˆ†æ',
          undefined,
          true
        );
      }

      // æ·»åŠ è¯­éŸ³è¯†åˆ«è®°å½•ï¼ˆæ— è®ºæ˜¯è‡ªåŠ¨è§¦å‘è¿˜æ˜¯æ‰‹åŠ¨è§¦å‘ï¼‰
      const speechRecord: OperationRecord = {
        id: `speech-${Date.now()}`,
        type: 'speech_recognition',
        timestamp: new Date(),
        status: 'success',
        message: (data.message as string) || 'è¯­éŸ³è¯†åˆ«å·²å®Œæˆ',
        data: {
          speech_result: data.result as string
        }
      };
      setOperationRecords(prev => [...prev, speechRecord]);
    } else if (data.type === 'audio_extraction_complete') {
      // æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨è§¦å‘è¯­éŸ³è¯†åˆ«
      if (data.auto_start_speech_recognition) {
        // è§¦å‘è‡ªåŠ¨è¯­éŸ³è¯†åˆ«
        triggerAutoSpeechRecognition();
      }
    } else if (data.type === 'video_understanding_complete') {
      // å‘é€é€šçŸ¥
      if (notificationEnabled) {
        notificationManager.sendNotification(
          'ğŸ¬ è§†é¢‘ç†è§£å®Œæˆ',
          'è§†é¢‘åˆ†æå·²å®Œæˆï¼ŒSOPè‰ç¨¿å·²ç”Ÿæˆï¼Œå¯ä»¥è¿›è¡Œè§£æ',
          undefined,
          true
        );
      }

      // æ·»åŠ è§†é¢‘ç†è§£è®°å½•
      const videoRecord: OperationRecord = {
        id: `video-${Date.now()}`,
        type: 'video_understanding',
        timestamp: new Date(),
        status: 'success',
        message: (data.message as string) || 'è§†é¢‘ç†è§£å·²å®Œæˆ',
        data: {
          video_result: typeof data.result === 'string' ? data.result : String(data.result),
          fps: data.fps as number | undefined,
          has_audio_context: data.has_audio_context as boolean | undefined
        }
      };
      setOperationRecords(prev => [...prev, videoRecord]);
      
      // ä¿å­˜è§†é¢‘ç†è§£ç»“æœ
      if (typeof data.result === 'string') {
        setVideoUnderstandingResult(data.result);
      }
    } else if (data.type === 'sop_parse_complete') {
      // å‘é€é€šçŸ¥
      if (notificationEnabled) {
        notificationManager.sendNotification(
          'ğŸ“‹ SOPè§£æå®Œæˆ',
          'SOPæ–‡æ¡£å·²è§£æä¸ºç»“æ„åŒ–åŒºå—ï¼Œå¯ä»¥è¿›è¡Œç¼–è¾‘å’Œç²¾ä¿®',
          undefined,
          true
        );
      }

      // æ·»åŠ SOPè§£æè®°å½•
      const parseRecord: OperationRecord = {
        id: `parse-${Date.now()}`,
        type: 'sop_parse',
        timestamp: new Date(),
        status: 'success',
        message: (data.message as string) || 'SOPè§£æå®Œæˆ',
          data: {
          blocks_count: data.blocks_count as number
        }
      };
      setOperationRecords(prev => [...prev, parseRecord]);
    } else if (data.type === 'sop_refine_complete') {
      // å‘é€é€šçŸ¥
      if (notificationEnabled) {
        notificationManager.sendNotification(
          'âœ¨ SOPç²¾ä¿®å®Œæˆ',
          'AIç²¾ä¿®å·²å®Œæˆï¼Œæ–‡æ¡£è´¨é‡å·²æå‡ï¼Œå¯ä»¥å¯¼å‡ºæœ€ç»ˆç‰ˆæœ¬',
          undefined,
          true
        );
      }

      // æ·»åŠ SOPç²¾ä¿®è®°å½•
      const refineRecord: OperationRecord = {
        id: `refine-${Date.now()}`,
        type: 'sop_refine',
        timestamp: new Date(),
        status: 'success',
        message: (data.message as string) || 'SOPç²¾ä¿®å®Œæˆ',
        data: {
          blocks_count: data.blocks_count as number,
          has_user_notes: data.has_user_notes as boolean
        }
      };
      setOperationRecords(prev => [...prev, refineRecord]);
    }
    // å‹ç¼©ç›¸å…³æ¶ˆæ¯ï¼šè½¬å‘ç»™VideoUploaderå¤„ç†å¹¶æ·»åŠ åˆ°æ“ä½œè®°å½•
    else if (data.type === 'compression_started') {
      // è®¾ç½®å‹ç¼©æ¶ˆæ¯çŠ¶æ€ï¼Œä¼ é€’ç»™VideoUploader
      setCompressionMessage(data);
      setCompressionStatus('compressing');
      
      // æ·»åŠ åˆ°æ“ä½œè®°å½•
      const compressionRecord: OperationRecord = {
        id: `compression-${Date.now()}`,
        type: 'video_compression',
        timestamp: new Date(),
        status: 'processing',
        message: data.message as string || 'å¼€å§‹å‹ç¼©è§†é¢‘...',
        data: { stage: 'compression_started' }
      };
      setOperationRecords(prev => [...prev, compressionRecord]);
    } else if (data.type === 'compression_progress') {
      // è½¬å‘ç»™VideoUploader
      setCompressionMessage(data);
      // ä¸æ·»åŠ åˆ°æ“ä½œè®°å½•ï¼ˆé¿å…è®°å½•è¿‡å¤šï¼‰
    } else if (data.type === 'compression_completed') {
      // è®¾ç½®å‹ç¼©æ¶ˆæ¯çŠ¶æ€ï¼Œä¼ é€’ç»™VideoUploader
      setCompressionMessage(data);
      setCompressionStatus('completed');
      
      // æ·»åŠ åˆ°æ“ä½œè®°å½•
      const compressionRecord: OperationRecord = {
        id: `compression-${Date.now()}`,
        type: 'video_compression',
        timestamp: new Date(),
        status: 'success',
        message: data.message as string || 'è§†é¢‘å‹ç¼©å®Œæˆï¼Œå·²åˆ é™¤åŸè§†é¢‘',
        data: { stage: 'compression_completed' }
      };
      setOperationRecords(prev => [...prev, compressionRecord]);
    } else if (data.type === 'compression_error') {
      // è®¾ç½®å‹ç¼©æ¶ˆæ¯çŠ¶æ€ï¼Œä¼ é€’ç»™VideoUploader
      setCompressionMessage(data);
      setCompressionStatus('error');
      
      // æ·»åŠ åˆ°æ“ä½œè®°å½•
      const compressionRecord: OperationRecord = {
        id: `compression-${Date.now()}`,
        type: 'video_compression',
        timestamp: new Date(),
        status: 'error',
        message: `è§†é¢‘å‹ç¼©å¤±è´¥: ${data.message || 'æœªçŸ¥é”™è¯¯'}`,
        data: { stage: 'compression_error' }
      };
      setOperationRecords(prev => [...prev, compressionRecord]);
    }
    // é˜¶æ®µæ€§çŠ¶æ€æ¶ˆæ¯ï¼šå†™å…¥æ“ä½œè®°å½•é¢æ¿
    else if (data.type === 'status') {
      const stage = (data.stage as string) || '';
      const message = (data.message as string) || 'çŠ¶æ€æ›´æ–°';
      const statusRecord: OperationRecord = {
        id: `status-${Date.now()}-${stage}`,
        type: 'video_understanding',
        timestamp: new Date(),
        status: 'success',
        message,
        data: { stage }
      };
      setOperationRecords(prev => [...prev, statusRecord]);
    }
    // é•¿è§†é¢‘åˆ†æ®µ/æ•´åˆäº‹ä»¶
    else if (data.type === 'segment_processing') {
      const segId = (data.segment_id as number) || 0;
      const timeRange = (data.time_range as string) || '';
      setSegmentResults(prev => {
        const exists = prev.find(s => s.segment_id === segId);
        if (exists) {
          return prev.map(s => s.segment_id === segId ? { ...s, status: 'processing', time_range: timeRange } : s);
        }
        return [...prev, { segment_id: segId, time_range: timeRange, result: '', status: 'processing' }];
      });
    } else if (data.type === 'segment_completed') {
      const segId = (data.segment_id as number) || 0;
      const timeRange = (data.time_range as string) || '';
      const text = (data.result as string) || '';
      setSegmentResults(prev => {
        const exists = prev.find(s => s.segment_id === segId);
        if (exists) {
          return prev.map(s => s.segment_id === segId ? { ...s, status: 'completed', time_range: timeRange, result: text } : s);
        }
        return [...prev, { segment_id: segId, time_range: timeRange, result: text, status: 'completed' }];
      });
      const segRecord: OperationRecord = {
        id: `segment-${Date.now()}-${segId}`,
        type: 'video_understanding',
        timestamp: new Date(),
        status: 'success',
        message: `ç‰‡æ®µ ${segId} å¤„ç†å®Œæˆ`,
        data: { segment_id: segId, time_range: timeRange }
      };
      setOperationRecords(prev => [...prev, segRecord]);
    } else if (data.type === 'integration_completed') {
      const text = typeof data.result === 'string' ? data.result : String(data.result || '');
      
      // ç¡®ä¿ç»“æœä¸ä¸ºç©ºæ‰æ›´æ–°çŠ¶æ€
      if (text && text.length > 0) {
        setIntegratedResult(text);
        setVideoUnderstandingResult(text); // åŒæ—¶è®¾ç½®videoUnderstandingResultä»¥ä¾¿SOPEditorå¯ä»¥ä½¿ç”¨
        
        const integRecord: OperationRecord = {
          id: `integrate-${Date.now()}`,
          type: 'video_understanding',
          timestamp: new Date(),
          status: 'success',
          message: 'é•¿è§†é¢‘æ•´åˆå®Œæˆ',
          data: {}
        };
        setOperationRecords(prev => [...prev, integRecord]);
      }
    }
  }, [notificationEnabled]);

  // WebSocket è¿æ¥ç”¨äºæ¥æ”¶æ“ä½œè®°å½•
  const { isConnected: wsConnected, sendMessage: sendWebSocketMessage, connect: reconnectWebSocket } = useWebSocket({
    onMessage: handleWebSocketMessage,
    clientSessionId: clientSessionId
  });

  // åˆå§‹åŒ–é€šçŸ¥æƒé™
  React.useEffect(() => {
    const initNotifications = async () => {
      const enabled = await notificationManager.initialize();
      setNotificationEnabled(enabled);
    };
    
    initNotifications();

    // ç›‘å¬é¡µé¢å¯è§æ€§å˜åŒ–
    notificationManager.onVisibilityChange((visible) => {
      console.log('é¡µé¢å¯è§æ€§å˜åŒ–:', visible);
    });

    // ç›‘å¬çª—å£ç„¦ç‚¹å˜åŒ–
    notificationManager.onFocusChange((focused) => {
      console.log('çª—å£ç„¦ç‚¹å˜åŒ–:', focused);
    });

  }, []);

  // å¤„ç†VideoUploaderçš„WebSocketæ¶ˆæ¯
  const handleVideoUploaderWebSocketMessage = (message: Record<string, unknown>) => {
    console.log('handleVideoUploaderWebSocketMessage:', message, 'wsConnected:', wsConnected);
    
    // å¦‚æœæ˜¯å‹ç¼©ç›¸å…³æ¶ˆæ¯ï¼Œç›´æ¥å¤„ç†ï¼Œä¸å‘é€åˆ°WebSocket
    if (message.type === 'compression_started' || 
        message.type === 'compression_completed' || 
        message.type === 'compression_error') {
      // è¿™äº›æ¶ˆæ¯å·²ç»åœ¨VideoUploaderå†…éƒ¨å¤„ç†äº†ï¼Œä¸éœ€è¦é¢å¤–æ“ä½œ
      return;
    }
    
    // å…¶ä»–æ¶ˆæ¯å‘é€åˆ°WebSocket
    if (sendWebSocketMessage) {
      try {
        console.log('å‘é€WebSocketæ¶ˆæ¯:', JSON.stringify(message));
        sendWebSocketMessage(JSON.stringify(message));
      } catch (error) {
        console.warn('å‘é€WebSocketæ¶ˆæ¯å¤±è´¥:', error);
        // ä¸æ˜¾ç¤ºé”™è¯¯ç»™ç”¨æˆ·ï¼Œå› ä¸ºä¼šè‡ªåŠ¨é‡è¿
      }
    } else {
      console.log('WebSocketæ¶ˆæ¯å‘é€å‡½æ•°ä¸å¯ç”¨');
    }
  };

  // è¯­éŸ³è¯†åˆ«å¤„ç†å‡½æ•°
  const handleSpeechRecognition = async (audioUrl: string) => {
    // ä»ç¯å¢ƒå˜é‡è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤5åˆ†é’Ÿ
    const timeoutMs = parseInt(process.env.NEXT_PUBLIC_SPEECH_RECOGNITION_TIMEOUT || '300000', 10);
    
    try {
      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
      
      const response = await fetch(API_ENDPOINTS.SPEECH_RECOGNITION, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          client_session_id: clientSessionId  // ä¸å†éœ€è¦audio_urlå‚æ•°
        }),
        mode: 'cors',
        credentials: 'omit',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      const speechResults = result.result || [];
      
      // ä¿å­˜è¯­éŸ³è¯†åˆ«ç»“æœåˆ°state
      setSpeechRecognitionResult(speechResults);
      
      return speechResults;
    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
      if (error instanceof Error && error.name === 'AbortError') {
        const timeoutMinutes = Math.round(timeoutMs / 60000);
        throw new Error(`è¯­éŸ³è¯†åˆ«è¶…æ—¶ï¼Œè¶…è¿‡ï¼ˆ${timeoutMinutes}åˆ†é’Ÿï¼‰ï¼Œè¯·æŠ¥å‘Šç»™Video2SOPç®¡ç†å‘˜ã€‚`);
      }
      
      throw error;
    }
  };

  // è‡ªåŠ¨è§¦å‘è¯­éŸ³è¯†åˆ«å‡½æ•°
  const triggerAutoSpeechRecognition = useCallback(() => {
    if (!clientSessionId) {
      console.warn('æ— æ³•è‡ªåŠ¨è§¦å‘è¯­éŸ³è¯†åˆ«ï¼šæœªæ‰¾åˆ°å®¢æˆ·ç«¯ä¼šè¯ID');
      return;
    }
    
    console.log('è‡ªåŠ¨è§¦å‘è¯­éŸ³è¯†åˆ«...');
    
    // è®¾ç½®è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çŠ¶æ€ï¼Œè®©SpeechRecognitionPanelçš„useEffectæ¥å¤„ç†
    setAutoSpeechRecognitionTriggered(true);
    setAutoSpeechRecognitionError(null);
  }, [clientSessionId]);

  // è§†é¢‘ç†è§£å¤„ç†å‡½æ•°
  const handleVideoUnderstanding = async (params: {
    video_url: string;
    prompt: string;
    fps: number;
    audio_transcript?: string;
    add_timestamp?: boolean;
    split_threshold?: number;
    segment_length?: number;
    segment_overlap?: number;
  }) => {
    // ä»ç¯å¢ƒå˜é‡è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤30åˆ†é’Ÿ
    const timeoutMs = parseInt(process.env.NEXT_PUBLIC_VIDEO_UNDERSTANDING_TIMEOUT || '1800000', 10);
    
    try {
      // ä¿å­˜ç”¨æˆ·æç¤ºè¯
      setVideoUnderstandingPrompt(params.prompt);
      
      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
      
      // ç»Ÿä¸€è°ƒç”¨é•¿è§†é¢‘ç«¯ç‚¹ï¼›çŸ­è§†é¢‘åœ¨åç«¯ä¼šç›´æ¥å¤„ç†
      // æ¸…ç†æ—§çš„åˆ†æ®µ/æ•´åˆUIçŠ¶æ€
      setSegmentResults([]);
      setIntegratedResult('');
      setVideoUnderstandingResult(''); // ä¹Ÿæ¸…ç©ºè§†é¢‘ç†è§£ç»“æœ
      const response = await fetch(API_ENDPOINTS.VIDEO_UNDERSTANDING_LONG, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          ...params,
          session_id: currentUploadResult?.session_id,
          client_session_id: clientSessionId
        }),
        mode: 'cors',
        credentials: 'omit',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      
      // å¯¹äºé•¿è§†é¢‘ï¼Œç»“æœå·²ç»é€šè¿‡WebSocketçš„integration_completedæ¶ˆæ¯è®¾ç½®ï¼Œä¸éœ€è¦å†ä»HTTPå“åº”ä¸­æå–
      // å¯¹äºçŸ­è§†é¢‘ï¼Œresult.resultåŒ…å«ç›´æ¥è¿”å›çš„ç†è§£ç»“æœ
      if (result.result) {
        const videoResult = result.result;
        setVideoUnderstandingResult(videoResult);
        return videoResult;
      } else {
        // é•¿è§†é¢‘ï¼šè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œå®é™…ç»“æœå·²é€šè¿‡WebSocketè®¾ç½®
        return '';
      }
    } catch (error) {
      console.error('è§†é¢‘ç†è§£å¤±è´¥:', error);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
      if (error instanceof Error && error.name === 'AbortError') {
        const timeoutMinutes = Math.round(timeoutMs / 60000);
        throw new Error(`è§†é¢‘ç†è§£è¶…æ—¶ï¼Œè¶…è¿‡ï¼ˆ${timeoutMinutes}åˆ†é’Ÿï¼‰ï¼Œè¯·æŠ¥å‘Šç»™Video2SOPç®¡ç†å‘˜ã€‚å¤æ‚è§†é¢‘çš„ç†è§£å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ã€‚`);
      }
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œé”™è¯¯
      if (error instanceof Error && error.message.includes('Failed to fetch')) {
        throw new Error('è§†é¢‘ç†è§£å¤±è´¥ï¼šç½‘ç»œè¿æ¥é—®é¢˜æˆ–æœåŠ¡å™¨é”™è¯¯ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ï¼Œæˆ–è”ç³»ç®¡ç†å‘˜ã€‚');
      }
      
      throw error;
    }
  };

  // SOPè§£æå¤„ç†å‡½æ•°
  const handleParseSOP = async (manuscript: string) => {
    // æ·»åŠ SOPæ‹†è§£å¼€å§‹è®°å½•
    const parseStartRecord: OperationRecord = {
      id: `parse-start-${Date.now()}`,
      type: 'sop_parse',
      timestamp: new Date(),
      status: 'processing',
      message: 'å¼€å§‹SOPæ‹†è§£',
    };
    setOperationRecords(prev => [...prev, parseStartRecord]);

    // ä»ç¯å¢ƒå˜é‡è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤20åˆ†é’Ÿ
    const timeoutMs = parseInt(process.env.NEXT_PUBLIC_SOP_PARSE_TIMEOUT || '1200000', 10);
    
    try {
      // ä¿å­˜è§£ææç¤ºè¯ï¼ˆä½¿ç”¨é»˜è®¤æç¤ºè¯ï¼‰
      setSopParsePrompt('è§£æSOPè‰ç¨¿ä¸ºç»“æ„åŒ–åŒºå—');
      
      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
      
      const response = await fetch(API_ENDPOINTS.PARSE_SOP, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          manuscript,
          client_session_id: clientSessionId
        }),
        // æ·»åŠ ä»£ç†ç»•è¿‡è®¾ç½®
        mode: 'cors',
        credentials: 'omit',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      return result.result;
    } catch (error) {
      console.error('SOPè§£æå¤±è´¥:', error);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
      if (error instanceof Error && error.name === 'AbortError') {
        const timeoutMinutes = Math.round(timeoutMs / 60000);
        throw new Error(`SOPè§£æè¶…æ—¶ï¼Œè¶…è¿‡ï¼ˆ${timeoutMinutes}åˆ†é’Ÿï¼‰ï¼Œè¯·æŠ¥å‘Šç»™Video2SOPç®¡ç†å‘˜ã€‚`);
      }
      
      throw error;
    }
  };

  // SOPç²¾ä¿®å¤„ç†å‡½æ•°
  const handleRefineSOP = async (blocks: SOPBlock[], userNotes: string) => {
    // ä»ç¯å¢ƒå˜é‡è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤20åˆ†é’Ÿ
    const timeoutMs = parseInt(process.env.NEXT_PUBLIC_SOP_REFINE_TIMEOUT || '1200000', 10);
    
    try {
      // ä¿å­˜ç²¾ä¿®æç¤ºè¯
      setSopRefinePrompt(userNotes || 'AIç²¾ä¿®SOPå†…å®¹');
      
      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
      
      const response = await fetch(API_ENDPOINTS.REFINE_SOP, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          blocks, 
          user_notes: userNotes,
          client_session_id: clientSessionId
        }),
        // æ·»åŠ ä»£ç†ç»•è¿‡è®¾ç½®
        mode: 'cors',
        credentials: 'omit',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      const refinedBlocks = result.result?.blocks || [];
      
      // ä¿å­˜ç²¾ä¿®ç»“æœ
      setRefinedSopBlocks(refinedBlocks);
      
      return result.result;
    } catch (error) {
      console.error('SOPç²¾ä¿®å¤±è´¥:', error);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
      if (error instanceof Error && error.name === 'AbortError') {
        const timeoutMinutes = Math.round(timeoutMs / 60000);
        throw new Error(`SOPç²¾ä¿®è¶…æ—¶ï¼Œè¶…è¿‡ï¼ˆ${timeoutMinutes}åˆ†é’Ÿï¼‰ï¼Œè¯·æŠ¥å‘Šç»™Video2SOPç®¡ç†å‘˜ã€‚`);
      }
      
      throw error;
    }
  };

  return (
    <ResizableLayout
      defaultSidebarWidth={320}
      minSidebarWidth={200}
      maxSidebarWidth={600}
      sidebar={
        <OperationHistory 
          records={operationRecords} 
          isConnected={wsConnected} 
          onReconnect={reconnectWebSocket}
          notificationEnabled={notificationEnabled}
          onNotificationToggle={async () => {
            try {
              console.log('ç‚¹å‡»å¯ç”¨é€šçŸ¥æŒ‰é’®');
              const enabled = await notificationManager.initialize();
              console.log('é€šçŸ¥æƒé™çŠ¶æ€:', enabled);
              setNotificationEnabled(enabled);
              
              if (enabled) {
                notificationManager.sendNotification(
                  'ğŸ”” é€šçŸ¥æµ‹è¯•',
                  'æµè§ˆå™¨é€šçŸ¥åŠŸèƒ½å·²å¯ç”¨ï¼'
                );
              }
            } catch (error) {
              console.error('å¯ç”¨é€šçŸ¥å¤±è´¥:', error);
              alert('å¯ç”¨é€šçŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨è®¾ç½®');
            }
          }}
          onNotificationTest={() => {
            notificationManager.sendNotification(
              'ğŸ”” é€šçŸ¥æµ‹è¯•',
              'è¿™æ˜¯ä¸€æ¡æµ‹è¯•é€šçŸ¥ï¼Œè¯æ˜é€šçŸ¥åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼'
            );
          }}
          onNotificationDisable={() => {
            notificationManager.disable();
            setNotificationEnabled(false);
          }}
          onNotificationSimulate={() => {
            notificationManager.sendNotification(
              'ğŸ¬ è§†é¢‘ç†è§£å®Œæˆ',
              'è§†é¢‘åˆ†æå·²å®Œæˆï¼ŒSOPè‰ç¨¿å·²ç”Ÿæˆï¼Œå¯ä»¥è¿›è¡Œè§£æ',
              undefined,
              true // forceå‚æ•°
            );
          }}
          currentUploadResult={currentUploadResult}
          speechRecognitionResult={speechRecognitionResult}
          videoUnderstandingResult={videoUnderstandingResult}
          videoUnderstandingPrompt={videoUnderstandingPrompt}
          clientSessionId={clientSessionId}
          sopBlocks={sopBlocks}
          refinedSopBlocks={refinedSopBlocks}
          sopParsePrompt={sopParsePrompt}
          sopRefinePrompt={sopRefinePrompt}
        />
      }
    >
      <div className="w-full max-w-6xl mx-auto px-4">
        <div className="text-center mb-6">
          <h1 className="text-3xl font-bold text-gray-900 mb-6">
            Video2SOPï¼šå°†ä»ªå™¨æ•™å­¦è§†é¢‘è½¬åŒ–ä¸ºSOP
          </h1>
        </div>


        {/* è§†é¢‘ä¸Šä¼ ç»„ä»¶ */}
        <div className="mb-6">
          <VideoUploader 
            clientSessionId={clientSessionId}
            onUploadStart={() => {
              // æ·»åŠ ä¸Šä¼ å¼€å§‹è®°å½•
              const uploadStartRecord: OperationRecord = {
                id: `upload-start-${Date.now()}`,
                type: 'upload',
                timestamp: new Date(),
                status: 'processing',
                message: 'å¼€å§‹è§†é¢‘ä¸Šä¼ ',
              };
              setOperationRecords(prev => [...prev, uploadStartRecord]);
            }}
            onUploadComplete={(result) => {
              setCurrentUploadResult(result);
              
              // ç›´æ¥æ·»åŠ æ“ä½œè®°å½•ï¼Œä¸ä¾èµ–WebSocket
              const uploadRecord: OperationRecord = {
                id: `upload-${Date.now()}`,
                type: 'upload',
                timestamp: new Date(),
                status: 'success',
                message: 'è§†é¢‘å’ŒéŸ³é¢‘ä¸Šä¼ å®Œæˆï¼',
                data: {
                  video_url: result.video_url,
                  audio_url: result.audio_url,
                  session_id: result.session_id
                }
              };
              setOperationRecords(prev => [...prev, uploadRecord]);
            }}
            onUploadError={(error) => {
              console.error('è§†é¢‘ä¸Šä¼ å¤±è´¥:', error);
            }}
            onFileRemoved={() => {
              setCurrentUploadResult(null);
              
              // é‡ç½®è‡ªåŠ¨è¯­éŸ³è¯†åˆ«çŠ¶æ€
              setAutoSpeechRecognitionTriggered(false);
              setAutoSpeechRecognitionError(null);
              
              // æ¸…é™¤æœ¬åœ°è§†é¢‘é¢„è§ˆURL
              setLocalVideoPreviewUrl(null);
              
              // ç›´æ¥æ·»åŠ åˆ é™¤è®°å½•ï¼Œä¸ä¾èµ–WebSocket
              const removeRecord: OperationRecord = {
                id: `remove-${Date.now()}`,
                type: 'file_removed',
                timestamp: new Date(),
                status: 'success',
                message: 'è§†é¢‘å’ŒéŸ³é¢‘å·²ä»OSSåˆ é™¤',
                data: {
                  deleted_count: 2
                }
              };
              setOperationRecords(prev => [...prev, removeRecord]);
            }}
            onVideoPreviewChange={(previewUrl) => {
              setLocalVideoPreviewUrl(previewUrl);
            }}
            onWebSocketMessage={handleVideoUploaderWebSocketMessage}
            compressionMessage={compressionMessage}
          />
        </div>

        {/* è¯­éŸ³è¯†åˆ«é¢æ¿ */}
        <div className="mb-6">
        <SpeechRecognitionPanel
          uploadResult={currentUploadResult}
          onSpeechRecognition={handleSpeechRecognition}
          onResultsChange={handleSpeechResultsChange}
          autoTriggered={autoSpeechRecognitionTriggered}
          autoError={autoSpeechRecognitionError}
          onAddOperationRecord={(record) => setOperationRecords(prev => [...prev, record])}
        />
        </div>
        
        {/* è§†é¢‘ç†è§£é¢æ¿ */}
        <div className="mb-6">
          <VideoUnderstandingPanel
            uploadResult={currentUploadResult}
            speechRecognitionResult={speechRecognitionResult}
            onVideoUnderstanding={handleVideoUnderstanding}
            segmentResults={segmentResults}
            integratedResult={integratedResult}
            compressionStatus={compressionStatus}
            autoSpeechRecognitionError={autoSpeechRecognitionError}
          />
        </div>

        {/* SOPç¼–è¾‘å™¨ */}
        <div className="mb-6">
          <SOPEditor
            manuscript={videoUnderstandingResult}
            videoUrl={localVideoPreviewUrl || currentUploadResult?.video_url}
            onParseSOP={handleParseSOP}
            onRefineSOP={handleRefineSOP}
            onBlocksChange={handleSopBlocksChange}
          />
        </div>
        
        {/* æŠ€æœ¯æ ˆ */}
        <div className="w-full max-w-7xl mx-auto mb-6">
          <div className="bg-white p-4 rounded-lg shadow-sm border">
            <h3 className="text-base font-semibold text-gray-800 mb-2">ğŸš€ æŠ€æœ¯æ ˆ</h3>
            <ul className="space-y-1 text-sm text-gray-600">
              <li>â€¢ <strong>AIæ¨¡å‹</strong>: Qwen3-VL-Plus (è§†é¢‘ç†è§£) + Paraformer-V2 (è¯­éŸ³è¯†åˆ«) + Qwen-Plus (æ–‡æœ¬å¤„ç†)</li>
              <li>â€¢ <strong>åç«¯</strong>: FastAPI + WebSocket + LangGraph Agent</li>
              <li>â€¢ <strong>å‰ç«¯</strong>: Next.js 15 + TypeScript + React 19 + Tailwind CSS</li>
              <li>â€¢ <strong>å­˜å‚¨</strong>: åç«¯æœåŠ¡å™¨å’Œé˜¿é‡Œäº‘OSS</li>
            </ul>
          </div>
        </div>
      </div>
    </ResizableLayout>
  );
}